{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe0ddb7",
   "metadata": {},
   "source": [
    "step 1 :Installing and importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfe254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from win32com.client import Dispatch\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a0a5c",
   "metadata": {},
   "source": [
    "Step 2: Designing the GUI and Loading the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(str1):\n",
    "    speak = Dispatch(\"SAPI.SpVoice\")\n",
    "    speak.Speak(str1)\n",
    "\n",
    "# Load the FaceNet model\n",
    "def load_facenet_model(json_path, weights_path):\n",
    "    with open(json_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    facenet_model = model_from_json(model_json)\n",
    "    facenet_model.load_weights(weights_path)\n",
    "    print(\"FaceNet model loaded successfully from JSON and weights.\")\n",
    "    return facenet_model\n",
    "\n",
    "# Paths to FaceNet model files\n",
    "facenet_json_path = r\"C:\\Users\\MY\\DSP1\\db\\facenet_model.json\"\n",
    "facenet_weights_path = r\"C:\\Users\\MY\\DSP1\\db\\facenet_model_weights.h5\"\n",
    "\n",
    "# Initialize FaceNet model\n",
    "facenet_model = load_facenet_model(facenet_json_path, facenet_weights_path)\n",
    "\n",
    "# Path to Haar Cascade XML for face detection\n",
    "facedetect = cv2.CascadeClassifier(r\"C:\\Users\\MY\\DSP1\\db\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load background image for the GUI\n",
    "imgBackground = cv2.imread(r\"C:\\Users\\MY\\yolov8\\roboflow screenshot\\background.png\")\n",
    "COL_NAMES = ['NAME:', 'TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721568a7",
   "metadata": {},
   "source": [
    "Step 3 Real-Time Attendance System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = facedetect.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in detected_faces:\n",
    "        crop_image = frame[y:y + h, x:x + w, :]\n",
    "        resized_img = cv2.resize(crop_image, (160, 160))  # Resize for FaceNet input\n",
    "        img_array = image.img_to_array(resized_img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        # Generate embeddings using FaceNet\n",
    "        embeddings = facenet_model.predict(img_array)\n",
    "\n",
    "        # Match the embedding with stored embeddings\n",
    "        output = \"Recognized_Person\"  # Replace with actual matching logic\n",
    "\n",
    "        # Record timestamp\n",
    "        ts = time.time()\n",
    "        date = datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n",
    "        timestamp = datetime.fromtimestamp(ts).strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # Draw rectangle and name on the frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, str(output), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Prepare attendance record\n",
    "        attendance = [str(output), str(timestamp)]\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = frame\n",
    "    cv2.imshow(\"Frame\", imgBackground)\n",
    "\n",
    "    # Save attendance on key press\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('o'):  # Press 'o' to save attendance\n",
    "        speak(\"Attendance Taken, Have a nice day!!\")\n",
    "        time.sleep(3)\n",
    "        save_attendance_to_csv(attendance, date)\n",
    "\n",
    "    if k == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03fb98",
   "metadata": {},
   "source": [
    "Step 4 Automatically Saving Attendance into CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5125fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_attendance_to_csv(attendance, date):\n",
    "    filename = \"Attendance/Attendance_\" + date + \".csv\"\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    if file_exists:\n",
    "        with open(filename, \"a\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(attendance)\n",
    "    else:\n",
    "        with open(filename, \"w\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(COL_NAMES)\n",
    "            writer.writerow(attendance)\n",
    "    print(f\"Attendance saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bf382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e829191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac33a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f97e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from win32com.client import Dispatch\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def speak(str1):\n",
    "    speak = Dispatch((\"SAPI.SpVoice\"))\n",
    "    speak.Speak(str1)\n",
    "\n",
    "# Load the FaceNet model\n",
    "model_path = 'path_to_your_facenet_model.h5'  # Specify the path to the FaceNet model\n",
    "facenet_model = load_model(model_path)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.resize(image, (160, 160))  # Resize to 160x160\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = (image - 127.5) / 127.5  # Normalize the image\n",
    "    return image\n",
    "\n",
    "def get_face_embedding(image, model):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    embedding = model.predict(preprocessed_image)\n",
    "    return embedding\n",
    "\n",
    "# Open the webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "facedetect = cv2.CascadeClassifier(r\"C:\\Users\\MY\\DSP1\\db\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load faces and names from CSV\n",
    "faces = pd.read_csv(r\"C:\\users\\my\\DSP1\\db\\faces.csv\", header=None).values  # Faces CSV should be embeddings\n",
    "names = pd.read_csv(r\"C:\\users\\my\\DSP1\\db\\names.csv\", header=None).values.flatten()  # Names CSV should be a single column of names\n",
    "\n",
    "print(f\"Faces length: {len(faces)}\")\n",
    "print(f\"Names length: {len(names)}\")\n",
    "\n",
    "# Check if faces and names have the same length\n",
    "if len(faces) == len(names):\n",
    "    # Precompute the embeddings for the known faces\n",
    "    known_face_embeddings = []\n",
    "    for face in faces:\n",
    "        known_face_embeddings.append(np.array(face))\n",
    "    known_face_embeddings = np.array(known_face_embeddings)\n",
    "else:\n",
    "    print(\"Error: The number of faces and names do not match.\")\n",
    "\n",
    "imgBackground = cv2.imread(r\"C:\\Users\\MY\\yolov8\\roboflow screenshot\\background.png\")\n",
    "\n",
    "COL_NAMES = ['NAME:', 'TIME']\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = facedetect.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in detected_faces:\n",
    "        crop_image = frame[y:y + h, x:x + w, :]\n",
    "        face_embedding = get_face_embedding(crop_image, facenet_model)\n",
    "\n",
    "        # Compare the face embedding with known faces\n",
    "        distances = []\n",
    "        for known_embedding in known_face_embeddings:\n",
    "            dist = cosine(face_embedding, known_embedding)  # Compute cosine similarity\n",
    "            distances.append(dist)\n",
    "\n",
    "        # Get the most similar face\n",
    "        min_distance_index = np.argmin(distances)\n",
    "        output = names[min_distance_index]  # The name of the recognized employee\n",
    "\n",
    "        ts = time.time()\n",
    "        date = datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n",
    "        timestamp = datetime.fromtimestamp(ts).strftime(\"%H : %M : %S\")\n",
    "        exist = os.path.isfile(\"Attendance/Attendance_\" + date + \".csv\")\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (50, 50, 255), 2)\n",
    "        cv2.rectangle(frame, (x, y - 40), (x + w, y), (50, 50, 255), -1)\n",
    "        cv2.putText(frame, str(output), (x, y - 15), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "\n",
    "        attendance = [str(output), str(timestamp)]\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = frame\n",
    "    cv2.imshow(\"Frame\", imgBackground)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('o'):\n",
    "        speak(\"Attendance Taken, Have a nice day!!\")\n",
    "        time.sleep(3)\n",
    "        if exist:\n",
    "            with open(\"Attendance/Attendance_\" + date + \".csv\", \"+a\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(attendance)\n",
    "            csvfile.close()\n",
    "        else:\n",
    "            with open(\"Attendance/Attendance_\" + date + \".csv\", \"+a\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(COL_NAMES)\n",
    "                writer.writerow(attendance)\n",
    "            csvfile.close()\n",
    "\n",
    "    if k == ord('o'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad8252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830dcad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a3ae22",
   "metadata": {},
   "source": [
    "Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from win32com.client import Dispatch\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753feac",
   "metadata": {},
   "source": [
    "Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07981ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(str1):\n",
    "    speak = Dispatch(\"SAPI.SpVoice\")\n",
    "    speak.Speak(str1)\n",
    "\n",
    "# Load the FaceNet model\n",
    "def load_facenet_model(json_path, weights_path):\n",
    "    with open(json_path, \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "    facenet_model = model_from_json(model_json)\n",
    "    facenet_model.load_weights(weights_path)\n",
    "    print(\"FaceNet model loaded successfully from JSON and weights.\")\n",
    "    return facenet_model\n",
    "\n",
    "# Paths to FaceNet model files\n",
    "facenet_json_path = r\"C:\\Users\\MY\\DSP1\\db\\facenet_model.json\"\n",
    "facenet_weights_path = r\"C:\\Users\\MY\\DSP1\\db\\facenet_model_weights.h5\"\n",
    "\n",
    "# Initialize FaceNet model\n",
    "facenet_model = load_facenet_model(facenet_json_path, facenet_weights_path)\n",
    "\n",
    "# Path to Haar Cascade XML for face detection\n",
    "facedetect = cv2.CascadeClassifier(r\"C:\\Users\\MY\\DSP1\\db\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load background image for the GUI\n",
    "imgBackground = cv2.imread(r\"C:\\Users\\MY\\yolov8\\roboflow screenshot\\background.png\")\n",
    "COL_NAMES = ['NAME:', 'TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24d6c3",
   "metadata": {},
   "source": [
    "Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to dataset images for known faces\n",
    "known_faces_dir = r'C:\\Users\\MY\\DSP1\\db\\train_augmented\\'  \n",
    "known_faces = ['LIM JING ROU', 'ANIS AQILAH', 'YU JIA ANN']  \n",
    "\n",
    "# Store embeddings for known faces\n",
    "known_embeddings = {}\n",
    "for person in known_faces:\n",
    "    img_path = os.path.join(known_faces_dir, person + '.jpg')\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = facedetect.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in detected_faces:\n",
    "        crop_image = img[y:y + h, x:x + w]\n",
    "        resized_img = cv2.resize(crop_image, (160, 160))  # Resize for FaceNet input\n",
    "        img_array = image.img_to_array(resized_img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        embedding = facenet_model.predict(img_array)\n",
    "        known_embeddings[person] = embedding\n",
    "\n",
    "# Function to find the best match from known faces\n",
    "def match_face(embedding):\n",
    "    min_distance = float('inf')\n",
    "    identified_person = \"Unknown\"\n",
    "    for person, known_embedding in known_embeddings.items():\n",
    "        distance = scipy.spatial.distance.euclidean(embedding, known_embedding)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            identified_person = person\n",
    "    return identified_person\n",
    "\n",
    "# Open the webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = facedetect.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in detected_faces:\n",
    "        crop_image = frame[y:y + h, x:x + w, :]\n",
    "        resized_img = cv2.resize(crop_image, (160, 160))  # Resize for FaceNet input\n",
    "        img_array = image.img_to_array(resized_img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        # Generate embeddings using FaceNet\n",
    "        embedding = facenet_model.predict(img_array)\n",
    "\n",
    "        # Match the embedding with stored embeddings\n",
    "        output = match_face(embedding)\n",
    "\n",
    "        # Record timestamp\n",
    "        ts = time.time()\n",
    "        date = datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n",
    "        timestamp = datetime.fromtimestamp(ts).strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # Draw rectangle and name on the frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, str(output), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Prepare attendance record\n",
    "        attendance = [str(output), str(timestamp)]\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = frame\n",
    "    cv2.imshow(\"Frame\", imgBackground)\n",
    "    \n",
    "    # Save attendance on key press\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('o'):  # Press 'o' to save attendance\n",
    "        speak(\"Attendance Taken, Have a nice day!!\")\n",
    "        time.sleep(3)\n",
    "        save_attendance_to_csv(attendance, date)\n",
    "\n",
    "    if k == ord('o'):  # Press 'o' to quit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561a491",
   "metadata": {},
   "source": [
    "Step 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5393e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save attendance to CSV\n",
    "def save_attendance_to_csv(attendance, date):\n",
    "    filename = \"Attendance/Attendance_\" + date + \".csv\"\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    if file_exists:\n",
    "        with open(filename, \"a\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(attendance)\n",
    "    else:\n",
    "        with open(filename, \"w\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(COL_NAMES)\n",
    "            writer.writerow(attendance)\n",
    "    print(f\"Attendance saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
